{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pytorch_transformers import BertTokenizer, BertForSequenceClassification, BertConfig, get_linear_schedule_with_warmup\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "dlg_list=[]\n",
    "with io.open(\"data/textandembedding/allmorptok_inputtextfile.txt\", encoding='euc-kr') as f:\n",
    "    for a in f:\n",
    "        b = a.strip().split('\\t')\n",
    "        dlg_list.append(b)\n",
    "\n",
    "dlg_df=pd.DataFrame(dlg_list, columns=[\"dialog\",'label'])\n",
    "dlg_df[\"label\"] = pd.to_numeric(dlg_df[\"label\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "numpy.int64"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dlg_df[\"label\"][0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tlsgh\\AppData\\Local\\Temp/ipykernel_7756/3012246228.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dialog_data_shuffled_token[\"dialog\"][idx] = tokenizer.tokenize(\"[CLS] \" + text + \" [SEP]\")\n"
     ]
    }
   ],
   "source": [
    "dialog_data_shuffled = dlg_df.sample(frac=1).reset_index(drop=True)\n",
    "dialog_data_shuffled_token = dialog_data_shuffled.copy()\n",
    "for idx, text in enumerate(dialog_data_shuffled_token[\"dialog\"]):\n",
    "    dialog_data_shuffled_token[\"dialog\"][idx] = tokenizer.tokenize(\"[CLS] \" + text + \" [SEP]\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                  dialog  label\n0      [[CLS], 안, ##녕, 하, 세, ##요, 코, ##디, 봇, 입, ##니다,...      1\n1      [[CLS], 안, ##녕, 하, 세, ##요, 코, ##디, 봇, 입, ##니다,...      1\n2      [[CLS], 어, ##서, 오, 세, ##요, 코, ##디, 봇, 입, ##니다,...      1\n3      [[CLS], 안, ##녕, 하, 세, ##요, 코, ##디, 봇, 입, ##니다,...      1\n4      [[CLS], 안, ##녕, 하, 세, ##요, 코, ##디, 봇, 입, ##니다,...      1\n...                                                  ...    ...\n58959  [[CLS], 안, ##녕, 하, 세, ##요, 코, ##디, 봇, 입, ##니다,...      0\n58960  [[CLS], 어, ##서, 오, 세, ##요, 코, ##디, 봇, 입, ##니다,...      0\n58961  [[CLS], 어, ##서, 오, 세, ##요, 코, ##디, 봇, 입, ##니다,...      1\n58962  [[CLS], 안, ##녕, 하, 세, ##요, 코, ##디, 봇, 입, ##니다,...      0\n58963  [[CLS], 안, ##녕, 하, 세, ##요, 코, ##디, 봇, 입, ##니다,...      0\n\n[58964 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dialog</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[[CLS], 안, ##녕, 하, 세, ##요, 코, ##디, 봇, 입, ##니다,...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[[CLS], 안, ##녕, 하, 세, ##요, 코, ##디, 봇, 입, ##니다,...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[[CLS], 어, ##서, 오, 세, ##요, 코, ##디, 봇, 입, ##니다,...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[[CLS], 안, ##녕, 하, 세, ##요, 코, ##디, 봇, 입, ##니다,...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[[CLS], 안, ##녕, 하, 세, ##요, 코, ##디, 봇, 입, ##니다,...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>58959</th>\n      <td>[[CLS], 안, ##녕, 하, 세, ##요, 코, ##디, 봇, 입, ##니다,...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>58960</th>\n      <td>[[CLS], 어, ##서, 오, 세, ##요, 코, ##디, 봇, 입, ##니다,...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>58961</th>\n      <td>[[CLS], 어, ##서, 오, 세, ##요, 코, ##디, 봇, 입, ##니다,...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>58962</th>\n      <td>[[CLS], 안, ##녕, 하, 세, ##요, 코, ##디, 봇, 입, ##니다,...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>58963</th>\n      <td>[[CLS], 안, ##녕, 하, 세, ##요, 코, ##디, 봇, 입, ##니다,...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>58964 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialog_data_shuffled_token"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tlsgh\\AppData\\Local\\Temp/ipykernel_7756/291199888.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dialog_data_shuffled_token[\"dialog\"][idx] = dialog_data_shuffled_token[\"dialog\"][idx][:512]\n"
     ]
    }
   ],
   "source": [
    "for idx, text in enumerate(dialog_data_shuffled_token[\"dialog\"]):\n",
    "    dialog_data_shuffled_token[\"dialog\"][idx] = dialog_data_shuffled_token[\"dialog\"][idx][:512]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "for idx, text in enumerate(dialog_data_shuffled_token[\"dialog\"]):\n",
    "    textlen = len(text)\n",
    "    if textlen == 512:\n",
    "        dialog_data_shuffled_token[\"dialog\"][idx][511] = \"[SEP]\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "max10=0\n",
    "for lt in dialog_data_shuffled_token[\"dialog\"]:\n",
    "    if max10 < len(lt):\n",
    "        max10=len(lt)\n",
    "print(max10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "for idx, text in enumerate(dialog_data_shuffled_token[\"dialog\"]):\n",
    "    textlen = len(text)\n",
    "    if textlen == 512:\n",
    "        text[-1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tlsgh\\AppData\\Local\\Temp/ipykernel_7756/3902430955.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dialog_data_shuffled_token[\"dialog\"][idx] = tokenizer.convert_tokens_to_ids(text)\n"
     ]
    }
   ],
   "source": [
    "for idx, text in enumerate(dialog_data_shuffled_token[\"dialog\"]):\n",
    "    dialog_data_shuffled_token[\"dialog\"][idx] = tokenizer.convert_tokens_to_ids(text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "[101,\n 9521,\n 118741,\n 9952,\n 9435,\n 48549,\n 9812,\n 48446,\n 9361,\n 9645,\n 48345,\n 9294,\n 119137,\n 9633,\n 9087,\n 12638,\n 9113,\n 85836,\n 118671,\n 48549,\n 8877,\n 78123,\n 9385,\n 12965,\n 9766,\n 17730,\n 9559,\n 8847,\n 9137,\n 9645,\n 8932,\n 9130,\n 118848,\n 9954,\n 9812,\n 48446,\n 9765,\n 38631,\n 9960,\n 9689,\n 9435,\n 48549,\n 9011,\n 9655,\n 14040,\n 9248,\n 8932,\n 11903,\n 26737,\n 9689,\n 9435,\n 48549,\n 9901,\n 12605,\n 119354,\n 9875,\n 9909,\n 118823,\n 9638,\n 9928,\n 12030,\n 15184,\n 9640,\n 9924,\n 11102,\n 9812,\n 48446,\n 9645,\n 48345,\n 9414,\n 10459,\n 9164,\n 9952,\n 10459,\n 9043,\n 9246,\n 32158,\n 9559,\n 9113,\n 9043,\n 28911,\n 9519,\n 9604,\n 21876,\n 9164,\n 9487,\n 51431,\n 9637,\n 9416,\n 14871,\n 9638,\n 9246,\n 32158,\n 9559,\n 9521,\n 9117,\n 9546,\n 48549,\n 9378,\n 118855,\n 9801,\n 30873,\n 9668,\n 68984,\n 9590,\n 9130,\n 118848,\n 9954,\n 9993,\n 41620,\n 9909,\n 118823,\n 9365,\n 60479,\n 9043,\n 9546,\n 118833,\n 24982,\n 48549,\n 9319,\n 14040,\n 9489,\n 35866,\n 119142,\n 9309,\n 48446,\n 8934,\n 9638,\n 78838,\n 9565,\n 100,\n 9942,\n 42769,\n 15184,\n 9944,\n 17342,\n 10739,\n 10003,\n 15001,\n 10003,\n 15001,\n 9913,\n 9657,\n 21155,\n 9113,\n 9162,\n 100,\n 9641,\n 13764,\n 9983,\n 9448,\n 100372,\n 9450,\n 101322,\n 9082,\n 9043,\n 9448,\n 100372,\n 118666,\n 10739,\n 9279,\n 9987,\n 42337,\n 9294,\n 118649,\n 9368,\n 9881,\n 16758,\n 100,\n 9954,\n 9487,\n 70122,\n 17138,\n 9555,\n 9043,\n 9102,\n 118679,\n 21614,\n 8843,\n 11261,\n 100,\n 9378,\n 118855,\n 9059,\n 41442,\n 9792,\n 16323,\n 119134,\n 9970,\n 118870,\n 9954,\n 9565,\n 42815,\n 9647,\n 9043,\n 8863,\n 55358,\n 9130,\n 118848,\n 9954,\n 102]"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialog_data_shuffled_token[\"dialog\"][0]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tlsgh\\AppData\\Local\\Temp/ipykernel_7756/3376163152.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dialog_data_shuffled_token[\"dialog\"][idx] = text + [0] * (512-text_len)\n"
     ]
    }
   ],
   "source": [
    "for idx, text in enumerate(dialog_data_shuffled_token[\"dialog\"]):\n",
    "    text_len=len(text)\n",
    "    dialog_data_shuffled_token[\"dialog\"][idx] = text + [0] * (512-text_len)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "512"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dialog_data_shuffled_token[\"dialog\"][0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "train = dialog_data_shuffled_token[:47170]\n",
    "test = dialog_data_shuffled_token[47170:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                  dialog  label\n0      [101, 9521, 118741, 9952, 9435, 48549, 9812, 4...      1\n1      [101, 9521, 118741, 9952, 9435, 48549, 9812, 4...      1\n2      [101, 9546, 12424, 9580, 9435, 48549, 9812, 48...      1\n3      [101, 9521, 118741, 9952, 9435, 48549, 9812, 4...      1\n4      [101, 9521, 118741, 9952, 9435, 48549, 9812, 4...      1\n...                                                  ...    ...\n47165  [101, 9521, 118741, 9952, 9435, 48549, 9812, 4...      1\n47166  [101, 9546, 12424, 9580, 9435, 48549, 9812, 48...      1\n47167  [101, 9521, 118741, 9952, 9435, 48549, 9812, 4...      1\n47168  [101, 9521, 118741, 9952, 9435, 48549, 9812, 4...      1\n47169  [101, 9521, 118741, 9952, 9435, 48549, 9812, 4...      1\n\n[47170 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dialog</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[101, 9521, 118741, 9952, 9435, 48549, 9812, 4...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[101, 9521, 118741, 9952, 9435, 48549, 9812, 4...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[101, 9546, 12424, 9580, 9435, 48549, 9812, 48...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[101, 9521, 118741, 9952, 9435, 48549, 9812, 4...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[101, 9521, 118741, 9952, 9435, 48549, 9812, 4...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>47165</th>\n      <td>[101, 9521, 118741, 9952, 9435, 48549, 9812, 4...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>47166</th>\n      <td>[101, 9546, 12424, 9580, 9435, 48549, 9812, 48...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>47167</th>\n      <td>[101, 9521, 118741, 9952, 9435, 48549, 9812, 4...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>47168</th>\n      <td>[101, 9521, 118741, 9952, 9435, 48549, 9812, 4...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>47169</th>\n      <td>[101, 9521, 118741, 9952, 9435, 48549, 9812, 4...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>47170 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "max = 0\n",
    "for text1 in train[\"dialog\"]:\n",
    "    if max < len(text1):\n",
    "        max = len(text1)\n",
    "print(max)\n",
    "max1 = 0\n",
    "for text2 in test[\"dialog\"]:\n",
    "    if max1 < len(text2):\n",
    "        max1 = len(text2)\n",
    "print(max1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어서 오 세요 코디 봇 입니다 무엇 을 도와 드릴까요 사촌 오빠 결혼식 에 참석 하 려는 데 입 고 갈 하객 룩 추천 해 주 세요 치마 바지 원피스 중 어떤 옷 이 포함 된 코디 로 추천 해 드릴까요 치마 가 포함 된 코디 요 선호 하 는 색상 이나 스타일 이 있 으신 가요 베이지 색상 을 선호 해요 잠시 만 기다려 주 세요 하객 룩 에 적절 한 단정 한 느낌 의 A 라인 스커트 가 포함 된 코디 입니다 요청 하 신 색상 에 맞춰 코디 해 보 았 습니다 마음 에 드 시 나요 아우 터만 다른 스타일 로 추천 해 주 세요 나머지 는 마음 에 들 어요 선호 하 시 는 색상 이나 스타일 이 있 으신 가요 깔끔 한 스타일 의 검은색 코트 였 으면 좋 겠 어요 잠시 만 기다려 주 세요 스트레이트 실루엣 으로 단정 한 느낌 을 주 며 울 혼방 으로 겨울 에 입 기 적절 한 코트 입니다 스트레이트 실루엣 미디 길 이 더블 여 밈 벨트 여 밈 테일 러드 칼라 드 랍 숄더 일자 형 소매 손등 덮 는 길 이 허리선 양쪽 패치 포켓 울 무광 불 투명 신축성 없 는 두꺼운 블랙 음악회 차분 한 여유 있 는 남녀 공용 의 단순 한 겨울 느낌 의\n",
      "['어', '##서', '오', '세', '##요', '코', '##디', '봇', '입', '##니다', '무', '##엇', '을', '도', '##와', '드', '##릴', '##까', '##요', '사', '##촌', '오', '##빠', '결', '##혼', '##식', '에', '참', '##석', '하', '려', '##는', '데', '입', '고', '갈', '하', '##객', '룩', '추', '##천', '해', '주', '세', '##요', '치', '##마', '바', '##지', '원', '##피', '##스', '중', '어떤', '옷', '이', '포', '##함', '된', '코', '##디', '로', '추', '##천', '해', '드', '##릴', '##까', '##요', '치', '##마', '가', '포', '##함', '된', '코', '##디', '요', '선', '##호', '하', '는', '색', '##상', '이', '##나', '스', '##타', '##일', '이', '있', '으', '##신', '가', '##요', '베', '##이지', '색', '##상', '을', '선', '##호', '해', '##요', '잠', '##시', '만', '기', '##다', '##려', '주', '세', '##요', '하', '##객', '룩', '에', '적', '##절', '한', '단', '##정', '한', '느', '##낌', '의', 'A', '라', '##인', '스', '##커', '##트', '가', '포', '##함', '된', '코', '##디', '입', '##니다', '요', '##청', '하', '신', '색', '##상', '에', '맞', '##춰', '코', '##디', '해', '보', '았', '습', '##니다', '마', '##음', '에', '드', '시', '나', '##요', '아', '##우', '터', '##만', '다른', '스', '##타', '##일', '로', '추', '##천', '해', '주', '세', '##요', '나', '##머', '##지', '는', '마', '##음', '에', '들', '어', '##요', '선', '##호', '하', '시', '는', '색', '##상', '이', '##나', '스', '##타', '##일', '이', '있', '으', '##신', '가', '##요', '깔', '##끔', '한', '스', '##타', '##일', '의', '검', '##은', '##색', '코', '##트', '였', '으', '##면', '좋', '겠', '어', '##요', '잠', '##시', '만', '기', '##다', '##려', '주', '세', '##요', '스', '##트', '##레', '##이트', '실', '##루', '##엣', '으로', '단', '##정', '한', '느', '##낌', '을', '주', '며', '울', '혼', '##방', '으로', '겨', '##울', '에', '입', '기', '적', '##절', '한', '코', '##트', '입', '##니다', '스', '##트', '##레', '##이트', '실', '##루', '##엣', '미', '##디', '길', '이', '더', '##블', '여', '[UNK]', '벨', '##트', '여', '[UNK]', '테', '##일', '러', '##드', '칼', '##라', '드', '랍', '[UNK]', '일', '##자', '형', '소', '##매', '손', '##등', '덮', '는', '길', '이', '허', '##리', '##선', '양', '##쪽', '패', '##치', '포', '##켓', '울', '무', '##광', '불', '투', '##명', '신', '##축', '##성', '없', '는', '두', '##꺼', '##운', '블', '##랙', '음악', '##회', '차', '##분', '한', '여', '##유', '있', '는', '남', '##녀', '공', '##용', '의', '단', '##순', '한', '겨', '##울', '느', '##낌', '의']\n"
     ]
    }
   ],
   "source": [
    "print(train[\"dialog\"][10])\n",
    "print(tokenizer.tokenize((train[\"dialog\"][10])))\n",
    "print(len(tokenizer.tokenize((train[\"dialog\"][10]))))\n",
    "print(tokenizer.covert_token_to_ids)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "class FashionDataset(Dataset):\n",
    "    ''' Naver Sentiment Movie Corpus Dataset '''\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.df.iloc[idx, 0]\n",
    "        label = self.df.iloc[idx, 1]\n",
    "        return text, label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "train_dataset = FashionDataset(train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([101]), tensor([9521]), tensor([118741]), tensor([9952]), tensor([9435]), tensor([48549]), tensor([9812]), tensor([48446]), tensor([9361]), tensor([9645]), tensor([48345]), tensor([9294]), tensor([119137]), tensor([9633]), tensor([9087]), tensor([12638]), tensor([9113]), tensor([85836]), tensor([118671]), tensor([48549]), tensor([8843]), tensor([52560]), tensor([9117]), tensor([8898]), tensor([9477]), tensor([88332]), tensor([41620]), tensor([13890]), tensor([9559]), tensor([9025]), tensor([9176]), tensor([8849]), tensor([48345]), tensor([9588]), tensor([9633]), tensor([9765]), tensor([38631]), tensor([9960]), tensor([9689]), tensor([9435]), tensor([48549]), tensor([9011]), tensor([9655]), tensor([14040]), tensor([9248]), tensor([8932]), tensor([11903]), tensor([26737]), tensor([9689]), tensor([9435]), tensor([48549]), tensor([9130]), tensor([118848]), tensor([9954]), tensor([9260]), tensor([75855]), tensor([118916]), tensor([9638]), tensor([9928]), tensor([48533]), tensor([9099]), tensor([9812]), tensor([48446]), tensor([9043]), tensor([9546]), tensor([118833]), tensor([24982]), tensor([48549]), tensor([8843]), tensor([48446]), tensor([71439]), tensor([9251]), tensor([8888]), tensor([9909]), tensor([118823]), tensor([9632]), tensor([9555]), tensor([9633]), tensor([118671]), tensor([48549]), tensor([9074]), tensor([9130]), tensor([118848]), tensor([9952]), tensor([8872]), tensor([9645]), tensor([8888]), tensor([9495]), tensor([9011]), tensor([48549]), tensor([9011]), tensor([9655]), tensor([14040]), tensor([9248]), tensor([8932]), tensor([11903]), tensor([26737]), tensor([9689]), tensor([9435]), tensor([48549]), tensor([9491]), tensor([119412]), tensor([32487]), tensor([9365]), tensor([9952]), tensor([9706]), tensor([9523]), tensor([9632]), tensor([9909]), tensor([118823]), tensor([9632]), tensor([9546]), tensor([118833]), tensor([24982]), tensor([48549]), tensor([9011]), tensor([8904]), tensor([119250]), tensor([9011]), tensor([48549]), tensor([9909]), tensor([118823]), tensor([9637]), tensor([9448]), tensor([36210]), tensor([9233]), tensor([9524]), tensor([26737]), tensor([9689]), tensor([9435]), tensor([48549]), tensor([8982]), tensor([18392]), tensor([42769]), tensor([10709]), tensor([110]), tensor([9931]), tensor([12692]), tensor([10533]), tensor([110]), tensor([9645]), tensor([48345]), tensor([9011]), tensor([9524]), tensor([8876]), tensor([9482]), tensor([48345]), tensor([9909]), tensor([118823]), tensor([9668]), tensor([68984]), tensor([9485]), tensor([30005]), tensor([12692]), tensor([9243]), tensor([9788]), tensor([17342]), tensor([78838]), tensor([100]), tensor([96567]), tensor([9580]), tensor([119411]), tensor([9983]), tensor([9565]), tensor([100]), tensor([9706]), tensor([68984]), tensor([9441]), tensor([9640]), tensor([9479]), tensor([12692]), tensor([52015]), tensor([9450]), tensor([68055]), tensor([9633]), tensor([9082]), tensor([9043]), tensor([9448]), tensor([100372]), tensor([118666]), tensor([10739]), tensor([9448]), tensor([100372]), tensor([8843]), tensor([11261]), tensor([9032]), tensor([119003]), tensor([9428]), tensor([9569]), tensor([8857]), tensor([9517]), tensor([9448]), tensor([100372]), tensor([8977]), tensor([9485]), tensor([30005]), tensor([12692]), tensor([9909]), tensor([118823]), tensor([9288]), tensor([9559]), tensor([9131]), tensor([9256]), tensor([9043]), tensor([100]), tensor([9558]), tensor([118787]), tensor([10739]), tensor([9233]), tensor([9408]), tensor([119236]), tensor([9082]), tensor([9043]), tensor([8934]), tensor([9638]), tensor([9531]), tensor([9109]), tensor([8843]), tensor([9202]), tensor([9032]), tensor([119003]), tensor([9428]), tensor([9569]), tensor([8857]), tensor([9517]), tensor([9531]), tensor([9109]), tensor([9942]), tensor([27654]), tensor([24982]), tensor([12605]), tensor([9157]), tensor([12030]), tensor([9686]), tensor([27355]), tensor([9519]), tensor([37388]), tensor([9405]), tensor([18471]), tensor([9617]), tensor([15184]), tensor([9928]), tensor([119304]), tensor([100]), tensor([9707]), tensor([66540]), tensor([9059]), tensor([9744]), tensor([12692]), tensor([9317]), tensor([24989]), tensor([9485]), tensor([30005]), tensor([12692]), tensor([9744]), tensor([12692]), tensor([9521]), tensor([105197]), tensor([8982]), tensor([18392]), tensor([42769]), tensor([10709]), tensor([110]), tensor([9931]), tensor([12692]), tensor([10533]), tensor([110]), tensor([9379]), tensor([119285]), tensor([9555]), tensor([9634]), tensor([9487]), tensor([70122]), tensor([17138]), tensor([9555]), tensor([9634]), tensor([9521]), tensor([8848]), tensor([9647]), tensor([9634]), tensor([9757]), tensor([89045]), tensor([78123]), tensor([120]), tensor([8877]), tensor([78123]), tensor([9603]), tensor([9378]), tensor([118855]), tensor([8942]), tensor([118707]), tensor([9954]), tensor([9491]), tensor([119412]), tensor([9954]), tensor([9059]), tensor([119064]), tensor([9954]), tensor([9288]), tensor([9559]), tensor([9256]), tensor([9043]), tensor([9365]), tensor([9952]), tensor([9706]), tensor([9523]), tensor([9632]), tensor([8885]), tensor([44321]), tensor([9909]), tensor([118823]), tensor([102]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0])] tensor([1])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_7756/2023824789.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[1;32mfor\u001B[0m \u001B[0mtext\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mlabel\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mtrain_loader\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mlabel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_7756/2023824789.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[1;32mfor\u001B[0m \u001B[0mtext\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mlabel\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mtrain_loader\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mlabel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_38_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_38_64.SafeCallWrapper.__call__\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_38_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_38_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_38_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_38_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_38_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_38_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_38_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_38_64.PyDBFrame.do_wait_suspend\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mC:\\Program Files\\JetBrains\\PyCharm 2021.2.1\\plugins\\python\\helpers\\pydev\\pydevd.py\u001B[0m in \u001B[0;36mdo_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[0;32m   1145\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1146\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_threads_suspended_single_notification\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnotify_thread_suspended\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mthread_id\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstop_reason\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1147\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_do_wait_suspend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marg\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msuspend_type\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfrom_this_thread\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1148\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1149\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_do_wait_suspend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mthread\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marg\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msuspend_type\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfrom_this_thread\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Program Files\\JetBrains\\PyCharm 2021.2.1\\plugins\\python\\helpers\\pydev\\pydevd.py\u001B[0m in \u001B[0;36m_do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[0;32m   1160\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1161\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprocess_internal_commands\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1162\u001B[1;33m                 \u001B[0mtime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msleep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0.01\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1163\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1164\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcancel_async_evaluation\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mget_current_thread_id\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mid\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mframe\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for text,label in train_loader:\n",
    "    print(text,label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n)"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased')\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tlsgh\\AppData\\Local\\Temp/ipykernel_7756/2571588945.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(label)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_7756/2571588945.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     20\u001B[0m         \u001B[0msample\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msample\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     21\u001B[0m         \u001B[0mlabels\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtensor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlabel\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 22\u001B[1;33m         \u001B[0moutputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msample\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mlabels\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     23\u001B[0m         \u001B[0mloss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlogits\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0moutputs\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m    887\u001B[0m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    888\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 889\u001B[1;33m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    890\u001B[0m         for hook in itertools.chain(\n\u001B[0;32m    891\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\pytorch_transformers\\modeling_bert.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input_ids, token_type_ids, attention_mask, labels, position_ids, head_mask)\u001B[0m\n\u001B[0;32m    960\u001B[0m     def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None,\n\u001B[0;32m    961\u001B[0m                 position_ids=None, head_mask=None):\n\u001B[1;32m--> 962\u001B[1;33m         outputs = self.bert(input_ids, position_ids=position_ids, token_type_ids=token_type_ids,\n\u001B[0m\u001B[0;32m    963\u001B[0m                             attention_mask=attention_mask, head_mask=head_mask)\n\u001B[0;32m    964\u001B[0m         \u001B[0mpooled_output\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0moutputs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m    887\u001B[0m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    888\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 889\u001B[1;33m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    890\u001B[0m         for hook in itertools.chain(\n\u001B[0;32m    891\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\pytorch_transformers\\modeling_bert.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input_ids, token_type_ids, attention_mask, position_ids, head_mask)\u001B[0m\n\u001B[0;32m    705\u001B[0m             \u001B[0mhead_mask\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconfig\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnum_hidden_layers\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    706\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 707\u001B[1;33m         \u001B[0membedding_output\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0membeddings\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput_ids\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mposition_ids\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mposition_ids\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtoken_type_ids\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtoken_type_ids\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    708\u001B[0m         encoder_outputs = self.encoder(embedding_output,\n\u001B[0;32m    709\u001B[0m                                        \u001B[0mextended_attention_mask\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m    887\u001B[0m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    888\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 889\u001B[1;33m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    890\u001B[0m         for hook in itertools.chain(\n\u001B[0;32m    891\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\pytorch_transformers\\modeling_bert.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input_ids, token_type_ids, position_ids)\u001B[0m\n\u001B[0;32m    242\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    243\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput_ids\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtoken_type_ids\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mposition_ids\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 244\u001B[1;33m         \u001B[0mseq_length\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0minput_ids\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    245\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mposition_ids\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    246\u001B[0m             \u001B[0mposition_ids\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mseq_length\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlong\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0minput_ids\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mIndexError\u001B[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(model.parameters(), lr=1e-6)\n",
    "\n",
    "itr = 1\n",
    "p_itr = 500\n",
    "epochs = 1\n",
    "total_loss = 0\n",
    "total_len = 0\n",
    "total_correct = 0\n",
    "MAX_LEN = 512 #최대 시퀀스 길이 설정\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    for text, label in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # encoding and zero padding\n",
    "\n",
    "        sample = torch.tensor(text)\n",
    "        sample, label = sample.to(device), label.to(device)\n",
    "        labels = torch.tensor(label)\n",
    "        outputs = model(sample, labels=labels)\n",
    "        loss, logits = outputs\n",
    "\n",
    "        pred = torch.argmax(F.softmax(logits), dim=1)\n",
    "        correct = pred.eq(labels)\n",
    "        total_correct += correct.sum().item()\n",
    "        total_len += len(labels)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if itr % p_itr == 0:\n",
    "            print('[Epoch {}/{}] Iteration {} -> Train Loss: {:.4f}, Accuracy: {:.3f}'.format(epoch+1, epochs, itr, total_loss/p_itr, total_correct/total_len))\n",
    "            total_loss = 0\n",
    "            total_len = 0\n",
    "            total_correct = 0\n",
    "\n",
    "        itr+=1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "torch.save(model,\"./data/bert1.pt\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 정확도 계산 함수\n",
    "def flat_accuracy(preds, labels):\n",
    "\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "\n",
    "# 시간 표시 함수\n",
    "def format_time(elapsed):\n",
    "\n",
    "    # 반올림\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "\n",
    "    # hh:mm:ss으로 형태 변경\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # 학습률(learning rate)\n",
    "                  eps = 1e-8\n",
    "                )\n",
    "\n",
    "# 에폭수\n",
    "epochs = 4\n",
    "\n",
    "# 총 훈련 스텝 : 배치반복 횟수 * 에폭\n",
    "total_steps = len(train_loader) * epochs\n",
    "\n",
    "# 스케줄러 생성\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "#그래디언트 초기화\n",
    "model.zero_grad()\n",
    "\n",
    "# 학습\n",
    "for epoch_i in range(0, epochs):\n",
    "\n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # 시작 시간 설정\n",
    "    t0 = time.time()\n",
    "\n",
    "    # 로스 초기화\n",
    "    total_loss = 0\n",
    "\n",
    "    # 훈련모드로 변경\n",
    "    model.train()\n",
    "\n",
    "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # 경과 정보 표시\n",
    "        if step % 500 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # 배치를 GPU에 넣음\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # 배치에서 데이터 추출\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        # Forward 수행\n",
    "        outputs = model(b_input_ids,\n",
    "                        token_type_ids=None,\n",
    "                        attention_mask=b_input_mask,\n",
    "                        labels=b_labels)\n",
    "\n",
    "        # 로스 구함\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # 총 로스 계산\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward 수행으로 그래디언트 계산\n",
    "        loss.backward()\n",
    "\n",
    "        # 그래디언트 클리핑\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # 그래디언트를 통해 가중치 파라미터 업데이트\n",
    "        optimizer.step()\n",
    "\n",
    "        # 스케줄러로 학습률 감소\n",
    "        scheduler.step()\n",
    "\n",
    "        # 그래디언트 초기화\n",
    "        model.zero_grad()\n",
    "\n",
    "    # 평균 로스 계산\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    #시작 시간 설정\n",
    "    t0 = time.time()\n",
    "\n",
    "    # 평가모드로 변경\n",
    "    model.eval()\n",
    "\n",
    "    # 변수 초기화\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "    for batch in validation_dataloader:\n",
    "        # 배치를 GPU에 넣음\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # 배치에서 데이터 추출\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        # 그래디언트 계산 안함\n",
    "        with torch.no_grad():\n",
    "            # Forward 수행\n",
    "            outputs = model(b_input_ids,\n",
    "                            token_type_ids=None,\n",
    "                            attention_mask=b_input_mask)\n",
    "\n",
    "        # 로스 구함\n",
    "        logits = outputs[0]\n",
    "\n",
    "        # CPU로 데이터 이동\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-2b894917",
   "language": "python",
   "display_name": "PyCharm (pythonProject2)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}