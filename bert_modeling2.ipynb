{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "dlg_list=[]\n",
    "with io.open(\"data/textandembedding/allmorptok_inputtextfile.txt\", encoding='euc-kr') as f:\n",
    "    for a in f:\n",
    "        b = a.strip().split('\\t')\n",
    "        dlg_list.append(b)\n",
    "\n",
    "dlg_df=pd.DataFrame(dlg_list, columns=[\"dialog\",'label'])\n",
    "dlg_df[\"label\"] = pd.to_numeric(dlg_df[\"label\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "numpy.int64"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dlg_df[\"label\"][0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tlsgh\\AppData\\Local\\Temp/ipykernel_6896/678777233.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dialog_data_shuffled_token[\"dialog\"][idx] = tokenizer.tokenize(\"[CLS] \" + text + \" [SEP]\")\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tlsgh\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3441, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\tlsgh\\AppData\\Local\\Temp/ipykernel_6896/678777233.py\", line 4, in <module>\n",
      "    dialog_data_shuffled_token[\"dialog\"][idx] = tokenizer.tokenize(\"[CLS] \" + text + \" [SEP]\")\n",
      "  File \"C:\\Users\\tlsgh\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\pandas\\core\\series.py\", line 1056, in __setitem__\n",
      "    cacher_needs_updating = self._check_is_chained_assignment_possible()\n",
      "  File \"C:\\Users\\tlsgh\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\pandas\\core\\series.py\", line 1211, in _check_is_chained_assignment_possible\n",
      "    if ref is not None and ref._is_mixed_type:\n",
      "  File \"C:\\Users\\tlsgh\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\pandas\\core\\generic.py\", line 5592, in _is_mixed_type\n",
      "    return self.dtypes.nunique() > 1\n",
      "  File \"C:\\Users\\tlsgh\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\pandas\\core\\base.py\", line 1017, in nunique\n",
      "    uniqs = self.unique()\n",
      "  File \"C:\\Users\\tlsgh\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\pandas\\core\\series.py\", line 2039, in unique\n",
      "    return super().unique()\n",
      "  File \"C:\\Users\\tlsgh\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\pandas\\core\\base.py\", line 979, in unique\n",
      "    result = unique1d(values)\n",
      "  File \"C:\\Users\\tlsgh\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\pandas\\core\\algorithms.py\", line 431, in unique\n",
      "    uniques = table.unique(values)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tlsgh\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tlsgh\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\tlsgh\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\tlsgh\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\tlsgh\\anaconda3\\envs\\fashionhow\\lib\\inspect.py\", line 1515, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\tlsgh\\anaconda3\\envs\\fashionhow\\lib\\inspect.py\", line 1473, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\tlsgh\\anaconda3\\envs\\fashionhow\\lib\\inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\tlsgh\\anaconda3\\envs\\fashionhow\\lib\\inspect.py\", line 754, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"C:\\Users\\tlsgh\\anaconda3\\envs\\fashionhow\\lib\\ntpath.py\", line 664, in realpath\n",
      "    if _getfinalpathname(spath) == path:\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tlsgh\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3441, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\tlsgh\\AppData\\Local\\Temp/ipykernel_6896/678777233.py\", line 4, in <module>\n",
      "    dialog_data_shuffled_token[\"dialog\"][idx] = tokenizer.tokenize(\"[CLS] \" + text + \" [SEP]\")\n",
      "  File \"C:\\Users\\tlsgh\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\pandas\\core\\series.py\", line 1056, in __setitem__\n",
      "    cacher_needs_updating = self._check_is_chained_assignment_possible()\n",
      "  File \"C:\\Users\\tlsgh\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\pandas\\core\\series.py\", line 1211, in _check_is_chained_assignment_possible\n",
      "    if ref is not None and ref._is_mixed_type:\n",
      "  File \"C:\\Users\\tlsgh\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\pandas\\core\\generic.py\", line 5592, in _is_mixed_type\n",
      "    return self.dtypes.nunique() > 1\n",
      "  File \"C:\\Users\\tlsgh\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\pandas\\core\\base.py\", line 1017, in nunique\n",
      "    uniqs = self.unique()\n",
      "  File \"C:\\Users\\tlsgh\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\pandas\\core\\series.py\", line 2039, in unique\n",
      "    return super().unique()\n",
      "  File \"C:\\Users\\tlsgh\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\pandas\\core\\base.py\", line 979, in unique\n",
      "    result = unique1d(values)\n",
      "  File \"C:\\Users\\tlsgh\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\pandas\\core\\algorithms.py\", line 431, in unique\n",
      "    uniques = table.unique(values)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tlsgh\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tlsgh\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3361, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\tlsgh\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3458, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\tlsgh\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2063, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "  File \"C:\\Users\\tlsgh\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1367, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"C:\\Users\\tlsgh\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1267, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"C:\\Users\\tlsgh\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1124, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"C:\\Users\\tlsgh\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\tlsgh\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tlsgh\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tlsgh\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\tlsgh\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\tlsgh\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\tlsgh\\anaconda3\\envs\\fashionhow\\lib\\inspect.py\", line 1515, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\tlsgh\\anaconda3\\envs\\fashionhow\\lib\\inspect.py\", line 1473, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\tlsgh\\anaconda3\\envs\\fashionhow\\lib\\inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\tlsgh\\anaconda3\\envs\\fashionhow\\lib\\inspect.py\", line 754, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"C:\\Users\\tlsgh\\anaconda3\\envs\\fashionhow\\lib\\ntpath.py\", line 664, in realpath\n",
      "    if _getfinalpathname(spath) == path:\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "    \u001B[1;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_6896/678777233.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0midx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtext\u001B[0m \u001B[1;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdialog_data_shuffled_token\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"dialog\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m         \u001B[0mdialog_data_shuffled_token\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"dialog\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0midx\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtokenizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtokenize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"[CLS] \"\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mtext\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;34m\" [SEP]\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\pandas\\core\\series.py\u001B[0m in \u001B[0;36m__setitem__\u001B[1;34m(self, key, value)\u001B[0m\n\u001B[0;32m   1055\u001B[0m         \u001B[0mkey\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcom\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply_if_callable\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1056\u001B[1;33m         \u001B[0mcacher_needs_updating\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_check_is_chained_assignment_possible\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1057\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\pandas\\core\\series.py\u001B[0m in \u001B[0;36m_check_is_chained_assignment_possible\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1210\u001B[0m             \u001B[0mref\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_get_cacher\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1211\u001B[1;33m             \u001B[1;32mif\u001B[0m \u001B[0mref\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mref\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_is_mixed_type\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1212\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_check_setitem_copy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstacklevel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m4\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"referent\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mforce\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\pandas\\core\\generic.py\u001B[0m in \u001B[0;36m_is_mixed_type\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   5591\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 5592\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtypes\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnunique\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   5593\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\pandas\\core\\base.py\u001B[0m in \u001B[0;36mnunique\u001B[1;34m(self, dropna)\u001B[0m\n\u001B[0;32m   1016\u001B[0m         \"\"\"\n\u001B[1;32m-> 1017\u001B[1;33m         \u001B[0muniqs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0munique\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1018\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mdropna\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\pandas\\core\\series.py\u001B[0m in \u001B[0;36munique\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   2038\u001B[0m         \"\"\"\n\u001B[1;32m-> 2039\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0munique\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2040\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\pandas\\core\\base.py\u001B[0m in \u001B[0;36munique\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    978\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 979\u001B[1;33m             \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0munique1d\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    980\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\pandas\\core\\algorithms.py\u001B[0m in \u001B[0;36munique\u001B[1;34m(values)\u001B[0m\n\u001B[0;32m    430\u001B[0m     \u001B[0mtable\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mhtable\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 431\u001B[1;33m     \u001B[0muniques\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtable\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0munique\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    432\u001B[0m     \u001B[0muniques\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_reconstruct_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0muniques\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moriginal\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moriginal\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m~\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001B[0m in \u001B[0;36mshowtraceback\u001B[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001B[0m\n\u001B[0;32m   2060\u001B[0m                         \u001B[1;31m# in the engines. This should return a list of strings.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2061\u001B[1;33m                         \u001B[0mstb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_render_traceback_\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2062\u001B[0m                     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001B[0m in \u001B[0;36mrun_ast_nodes\u001B[1;34m(self, nodelist, cell_name, interactivity, compiler, result)\u001B[0m\n\u001B[0;32m   3360\u001B[0m                         \u001B[0masy\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcompare\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcode\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3361\u001B[1;33m                     \u001B[1;32mif\u001B[0m \u001B[1;33m(\u001B[0m\u001B[1;32mawait\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrun_code\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcode\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mresult\u001B[0m\u001B[1;33m,\u001B[0m  \u001B[0masync_\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0masy\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3362\u001B[0m                         \u001B[1;32mreturn\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "    \u001B[1;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001B[0m in \u001B[0;36mshowtraceback\u001B[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001B[0m\n\u001B[0;32m   2062\u001B[0m                     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2063\u001B[1;33m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001B[0m\u001B[0;32m   2064\u001B[0m                                             value, tb, tb_offset=tb_offset)\n",
      "\u001B[1;32m~\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\IPython\\core\\ultratb.py\u001B[0m in \u001B[0;36mstructured_traceback\u001B[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[0;32m   1366\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtb\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1367\u001B[1;33m         return FormattedTB.structured_traceback(\n\u001B[0m\u001B[0;32m   1368\u001B[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "\u001B[1;32m~\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\IPython\\core\\ultratb.py\u001B[0m in \u001B[0;36mstructured_traceback\u001B[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[0;32m   1266\u001B[0m             \u001B[1;31m# Verbose modes need a full traceback\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1267\u001B[1;33m             return VerboseTB.structured_traceback(\n\u001B[0m\u001B[0;32m   1268\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0metype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtb\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtb_offset\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnumber_of_lines_of_context\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\IPython\\core\\ultratb.py\u001B[0m in \u001B[0;36mstructured_traceback\u001B[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[0;32m   1123\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1124\u001B[1;33m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001B[0m\u001B[0;32m   1125\u001B[0m                                                                tb_offset)\n",
      "\u001B[1;32m~\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\IPython\\core\\ultratb.py\u001B[0m in \u001B[0;36mformat_exception_as_a_whole\u001B[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001B[0m\n\u001B[0;32m   1081\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1082\u001B[1;33m         \u001B[0mlast_unique\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrecursion_repeat\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfind_recursion\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0morig_etype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevalue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrecords\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1083\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\IPython\\core\\ultratb.py\u001B[0m in \u001B[0;36mfind_recursion\u001B[1;34m(etype, value, records)\u001B[0m\n\u001B[0;32m    381\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mis_recursion_error\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0metype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrecords\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 382\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrecords\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    383\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: object of type 'NoneType' has no len()",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m~\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001B[0m in \u001B[0;36mshowtraceback\u001B[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001B[0m\n\u001B[0;32m   2060\u001B[0m                         \u001B[1;31m# in the engines. This should return a list of strings.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2061\u001B[1;33m                         \u001B[0mstb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_render_traceback_\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2062\u001B[0m                     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'TypeError' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\IPython\\core\\async_helpers.py\u001B[0m in \u001B[0;36m_pseudo_sync_runner\u001B[1;34m(coro)\u001B[0m\n\u001B[0;32m     66\u001B[0m     \"\"\"\n\u001B[0;32m     67\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 68\u001B[1;33m         \u001B[0mcoro\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     69\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mStopIteration\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mexc\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     70\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mexc\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001B[0m in \u001B[0;36mrun_cell_async\u001B[1;34m(self, raw_cell, store_history, silent, shell_futures, transformed_cell, preprocessing_exc_tuple)\u001B[0m\n\u001B[0;32m   3167\u001B[0m                     \u001B[0minteractivity\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m'async'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3168\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3169\u001B[1;33m                 has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n\u001B[0m\u001B[0;32m   3170\u001B[0m                        interactivity=interactivity, compiler=compiler, result=result)\n\u001B[0;32m   3171\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001B[0m in \u001B[0;36mrun_ast_nodes\u001B[1;34m(self, nodelist, cell_name, interactivity, compiler, result)\u001B[0m\n\u001B[0;32m   3378\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mresult\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3379\u001B[0m                 \u001B[0mresult\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0merror_before_exec\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msys\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexc_info\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3380\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshowtraceback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3381\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3382\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001B[0m in \u001B[0;36mshowtraceback\u001B[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001B[0m\n\u001B[0;32m   2061\u001B[0m                         \u001B[0mstb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_render_traceback_\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2062\u001B[0m                     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2063\u001B[1;33m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001B[0m\u001B[0;32m   2064\u001B[0m                                             value, tb, tb_offset=tb_offset)\n\u001B[0;32m   2065\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\IPython\\core\\ultratb.py\u001B[0m in \u001B[0;36mstructured_traceback\u001B[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[0;32m   1365\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1366\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtb\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1367\u001B[1;33m         return FormattedTB.structured_traceback(\n\u001B[0m\u001B[0;32m   1368\u001B[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001B[0;32m   1369\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\IPython\\core\\ultratb.py\u001B[0m in \u001B[0;36mstructured_traceback\u001B[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[0;32m   1265\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mmode\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mverbose_modes\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1266\u001B[0m             \u001B[1;31m# Verbose modes need a full traceback\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1267\u001B[1;33m             return VerboseTB.structured_traceback(\n\u001B[0m\u001B[0;32m   1268\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0metype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtb\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtb_offset\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnumber_of_lines_of_context\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1269\u001B[0m             )\n",
      "\u001B[1;32m~\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\IPython\\core\\ultratb.py\u001B[0m in \u001B[0;36mstructured_traceback\u001B[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001B[0m\n\u001B[0;32m   1140\u001B[0m         \u001B[0mchained_exc_ids\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1141\u001B[0m         \u001B[1;32mwhile\u001B[0m \u001B[0mevalue\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1142\u001B[1;33m             formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n\u001B[0m\u001B[0;32m   1143\u001B[0m                                                                      chained_exceptions_tb_offset)\n\u001B[0;32m   1144\u001B[0m             \u001B[0mexception\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget_parts_of_chained_exception\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mevalue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\IPython\\core\\ultratb.py\u001B[0m in \u001B[0;36mformat_exception_as_a_whole\u001B[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001B[0m\n\u001B[0;32m   1080\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1081\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1082\u001B[1;33m         \u001B[0mlast_unique\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrecursion_repeat\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfind_recursion\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0morig_etype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevalue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrecords\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1083\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1084\u001B[0m         \u001B[0mframes\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat_records\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrecords\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlast_unique\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrecursion_repeat\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\fashionhow\\lib\\site-packages\\IPython\\core\\ultratb.py\u001B[0m in \u001B[0;36mfind_recursion\u001B[1;34m(etype, value, records)\u001B[0m\n\u001B[0;32m    380\u001B[0m     \u001B[1;31m# first frame (from in to out) that looks different.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    381\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mis_recursion_error\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0metype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrecords\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 382\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrecords\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    383\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    384\u001B[0m     \u001B[1;31m# Select filename, lineno, func_name to track frames with\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "dialog_data_shuffled = dlg_df.sample(frac=1).reset_index(drop=True)\n",
    "dialog_data_shuffled_token = dialog_data_shuffled.copy()\n",
    "for idx, text in enumerate(dialog_data_shuffled_token[\"dialog\"]):\n",
    "        dialog_data_shuffled_token[\"dialog\"][idx] = tokenizer.tokenize(\"[CLS] \" + text + \" [SEP]\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dialog_data_shuffled_token"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for idx, text in enumerate(dialog_data_shuffled_token[\"dialog\"]):\n",
    "    dialog_data_shuffled_token[\"dialog\"][idx] = dialog_data_shuffled_token[\"dialog\"][idx][:512]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for idx, text in enumerate(dialog_data_shuffled_token[\"dialog\"]):\n",
    "    textlen = len(text)\n",
    "    if textlen == 512:\n",
    "        dialog_data_shuffled_token[\"dialog\"][idx][511] = \"[SEP]\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "max10=0\n",
    "for lt in dialog_data_shuffled_token[\"dialog\"]:\n",
    "    if max10 < len(lt):\n",
    "        max10=len(lt)\n",
    "print(max10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for idx, text in enumerate(dialog_data_shuffled_token[\"dialog\"]):\n",
    "    textlen = len(text)\n",
    "    if textlen == 512:\n",
    "        text[-1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for idx, text in enumerate(dialog_data_shuffled_token[\"dialog\"]):\n",
    "    dialog_data_shuffled_token[\"dialog\"][idx] = tokenizer.convert_tokens_to_ids(text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "[101,\n 9521,\n 118741,\n 9952,\n 9435,\n 48549,\n 9812,\n 48446,\n 9361,\n 9645,\n 48345,\n 9294,\n 119137,\n 9633,\n 9087,\n 12638,\n 9113,\n 85836,\n 118671,\n 48549,\n 9638,\n 35465,\n 9565,\n 49543,\n 10013,\n 11287,\n 9137,\n 8843,\n 52560,\n 8898,\n 19653,\n 8887,\n 55670,\n 29805,\n 9299,\n 118744,\n 10739,\n 9233,\n 8847,\n 8887,\n 103155,\n 9638,\n 9559,\n 48549,\n 9299,\n 118744,\n 9638,\n 8847,\n 9137,\n 9645,\n 9633,\n 9664,\n 58931,\n 9954,\n 9588,\n 9633,\n 9765,\n 38631,\n 9960,\n 9689,\n 9435,\n 48549,\n 9011,\n 9655,\n 14040,\n 9248,\n 8932,\n 11903,\n 26737,\n 9689,\n 9435,\n 48549,\n 9542,\n 8888,\n 9487,\n 70122,\n 17138,\n 9638,\n 9647,\n 9043,\n 9519,\n 10739,\n 108366,\n 9633,\n 9996,\n 24974,\n 9960,\n 9565,\n 49543,\n 9559,\n 9645,\n 8932,\n 9685,\n 9632,\n 9812,\n 48446,\n 9645,\n 48345,\n 9457,\n 15184,\n 9332,\n 9128,\n 9911,\n 60479,\n 9294,\n 118905,\n 9619,\n 9202,\n 9580,\n 9043,\n 9717,\n 9632,\n 8934,\n 9638,\n 9332,\n 9128,\n 9968,\n 12692,\n 9744,\n 12692,\n 9318,\n 12508,\n 9575,\n 9479,\n 118856,\n 15184,\n 9689,\n 118920,\n 25503,\n 96567,\n 9664,\n 9640,\n 9812,\n 119372,\n 9186,\n 48653,\n 9909,\n 57346,\n 9080,\n 9072,\n 9612,\n 24989,\n 9619,\n 9559,\n 9080,\n 14423,\n 9546,\n 9708,\n 9812,\n 119372,\n 9186,\n 48653,\n 9122,\n 119351,\n 18392,\n 9202,\n 39629,\n 9317,\n 24989,\n 9365,\n 37712,\n 9559,\n 9186,\n 78136,\n 9157,\n 12030,\n 9638,\n 9379,\n 119277,\n 9202,\n 118916,\n 119375,\n 9954,\n 9367,\n 19855,\n 12310,\n 9233,\n 9568,\n 52363,\n 16139,\n 9812,\n 119372,\n 117,\n 9931,\n 12692,\n 117,\n 9186,\n 48653,\n 9987,\n 42337,\n 9487,\n 70122,\n 9434,\n 9539,\n 18784,\n 9647,\n 9634,\n 9664,\n 21928,\n 9954,\n 9102,\n 118683,\n 8848,\n 9379,\n 119285,\n 9555,\n 9634,\n 9059,\n 80331,\n 9450,\n 24982,\n 119335,\n 9113,\n 17342,\n 10739,\n 119327,\n 12692,\n 106065,\n 8917,\n 13890,\n 9379,\n 119285,\n 9689,\n 9637,\n 9186,\n 48653,\n 9583,\n 9937,\n 67527,\n 9689,\n 9637,\n 9542,\n 8888,\n 8843,\n 118983,\n 21614,\n 9731,\n 24974,\n 105197,\n 29805,\n 9565,\n 49543,\n 9559,\n 9664,\n 33188,\n 9954,\n 9519,\n 10739,\n 30005,\n 12692,\n 9801,\n 30873,\n 8888,\n 16758,\n 9087,\n 9637,\n 9519,\n 10739,\n 30005,\n 12692,\n 9801,\n 30873,\n 9202,\n 9324,\n 8888,\n 9993,\n 12945,\n 9954,\n 9041,\n 118710,\n 100,\n 9689,\n 12965,\n 9360,\n 8898,\n 9565,\n 49543,\n 9559,\n 9524,\n 118913,\n 9632,\n 9416,\n 105197,\n 9638,\n 9056,\n 9996,\n 18778,\n 9664,\n 9638,\n 8888,\n 9924,\n 11102,\n 71771,\n 12508,\n 8920,\n 119145,\n 8888,\n 9323,\n 118852,\n 9954,\n 9202,\n 118916,\n 119375,\n 9954,\n 9792,\n 16323,\n 119134,\n 9954,\n 9083,\n 18392,\n 12692,\n 9214,\n 9083,\n 41620,\n 9214,\n 9946,\n 20308,\n 118766,\n 9214,\n 9318,\n 119290,\n 12605,\n 9214,\n 102]"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialog_data_shuffled_token[\"dialog\"][0]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tlsgh\\AppData\\Local\\Temp/ipykernel_22292/2015811903.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dialog_data_shuffled_token[\"dialog\"][idx] = text + [0] * (512-text_len)\n"
     ]
    }
   ],
   "source": [
    "for idx, text in enumerate(dialog_data_shuffled_token[\"dialog\"]):\n",
    "    text_len=len(text)\n",
    "    dialog_data_shuffled_token[\"dialog\"][idx] = text + [0] * (512-text_len)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "512"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dialog_data_shuffled_token[\"dialog\"][0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "train = dialog_data_shuffled_token[:47170]\n",
    "test = dialog_data_shuffled_token[47170:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                  dialog  label\n0      [101, 9521, 118741, 9952, 9435, 48549, 9812, 4...      1\n1      [101, 9546, 12424, 9580, 9435, 48549, 8888, 11...      0\n2      [101, 9521, 118741, 9952, 9435, 48549, 9812, 4...      1\n3      [101, 9521, 118741, 9952, 9435, 48549, 9812, 4...      1\n4      [101, 9521, 118741, 9952, 9435, 48549, 9812, 4...      0\n...                                                  ...    ...\n47165  [101, 9521, 118741, 9952, 9435, 48549, 9812, 4...      0\n47166  [101, 9521, 118741, 9952, 9435, 48549, 9812, 4...      1\n47167  [101, 9521, 118741, 9952, 9435, 48549, 9812, 4...      0\n47168  [101, 9521, 118741, 9952, 9435, 48549, 9812, 4...      1\n47169  [101, 9546, 12424, 9580, 9435, 48549, 9812, 48...      1\n\n[47170 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dialog</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[101, 9521, 118741, 9952, 9435, 48549, 9812, 4...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[101, 9546, 12424, 9580, 9435, 48549, 8888, 11...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[101, 9521, 118741, 9952, 9435, 48549, 9812, 4...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[101, 9521, 118741, 9952, 9435, 48549, 9812, 4...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[101, 9521, 118741, 9952, 9435, 48549, 9812, 4...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>47165</th>\n      <td>[101, 9521, 118741, 9952, 9435, 48549, 9812, 4...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>47166</th>\n      <td>[101, 9521, 118741, 9952, 9435, 48549, 9812, 4...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>47167</th>\n      <td>[101, 9521, 118741, 9952, 9435, 48549, 9812, 4...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>47168</th>\n      <td>[101, 9521, 118741, 9952, 9435, 48549, 9812, 4...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>47169</th>\n      <td>[101, 9546, 12424, 9580, 9435, 48549, 9812, 48...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>47170 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "max = 0\n",
    "for text1 in train[\"dialog\"]:\n",
    "    if max < len(text1):\n",
    "        max = len(text1)\n",
    "print(max)\n",
    "max1 = 0\n",
    "for text2 in test[\"dialog\"]:\n",
    "    if max1 < len(text2):\n",
    "        max1 = len(text2)\n",
    "print(max1)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "input_ids = list(dialog_data_shuffled_token[\"dialog\"])\n",
    "labels = list(dialog_data_shuffled_token[\"label\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "attention_masks = []\n",
    "\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_masks.append(seq_mask)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids,labels,random_state=2000,test_size=0.2)\n",
    "\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks,input_ids,random_state=2000,test_size=0.2)\n",
    "\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "validation_masks = torch.tensor(validation_masks)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 2080 SUPER\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('No GPU available, using the CPU instead.')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": "BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n)"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=2)\n",
    "model.cuda()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # 학습률(learning rate)\n",
    "                  eps = 1e-8\n",
    "                )\n",
    "\n",
    "# 에폭수\n",
    "epochs = 4\n",
    "\n",
    "# 총 훈련 스텝 : 배치반복 횟수 * 에폭\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# 스케줄러 생성\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def flat_accuracy(preds, labels):\n",
    "\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "\n",
    "# 시간 표시 함수\n",
    "def format_time(elapsed):\n",
    "\n",
    "    # 반올림\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "\n",
    "    # hh:mm:ss으로 형태 변경\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "  Batch   500  of  11,793.    Elapsed: 0:01:57.\n",
      "  Batch 1,000  of  11,793.    Elapsed: 0:03:54.\n",
      "  Batch 1,500  of  11,793.    Elapsed: 0:05:52.\n",
      "  Batch 2,000  of  11,793.    Elapsed: 0:07:50.\n",
      "  Batch 2,500  of  11,793.    Elapsed: 0:09:53.\n",
      "  Batch 3,000  of  11,793.    Elapsed: 0:12:00.\n",
      "  Batch 3,500  of  11,793.    Elapsed: 0:14:03.\n",
      "  Batch 4,000  of  11,793.    Elapsed: 0:16:05.\n",
      "  Batch 4,500  of  11,793.    Elapsed: 0:18:10.\n",
      "  Batch 5,000  of  11,793.    Elapsed: 0:20:12.\n",
      "  Batch 5,500  of  11,793.    Elapsed: 0:22:14.\n",
      "  Batch 6,000  of  11,793.    Elapsed: 0:24:16.\n",
      "  Batch 6,500  of  11,793.    Elapsed: 0:26:17.\n",
      "  Batch 7,000  of  11,793.    Elapsed: 0:28:19.\n",
      "  Batch 7,500  of  11,793.    Elapsed: 0:30:20.\n",
      "  Batch 8,000  of  11,793.    Elapsed: 0:32:18.\n",
      "  Batch 8,500  of  11,793.    Elapsed: 0:34:16.\n",
      "  Batch 9,000  of  11,793.    Elapsed: 0:36:16.\n",
      "  Batch 9,500  of  11,793.    Elapsed: 0:38:16.\n",
      "  Batch 10,000  of  11,793.    Elapsed: 0:40:15.\n",
      "  Batch 10,500  of  11,793.    Elapsed: 0:42:14.\n",
      "  Batch 11,000  of  11,793.    Elapsed: 0:44:15.\n",
      "  Batch 11,500  of  11,793.    Elapsed: 0:46:14.\n",
      "\n",
      "  Average training loss: 0.67\n",
      "  Training epcoh took: 0:47:23\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.61\n",
      "  Validation took: 0:03:10\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch   500  of  11,793.    Elapsed: 0:01:58.\n",
      "  Batch 1,000  of  11,793.    Elapsed: 0:03:57.\n",
      "  Batch 1,500  of  11,793.    Elapsed: 0:05:56.\n",
      "  Batch 2,000  of  11,793.    Elapsed: 0:07:55.\n",
      "  Batch 2,500  of  11,793.    Elapsed: 0:09:53.\n",
      "  Batch 3,000  of  11,793.    Elapsed: 0:11:51.\n",
      "  Batch 3,500  of  11,793.    Elapsed: 0:13:50.\n",
      "  Batch 4,000  of  11,793.    Elapsed: 0:15:48.\n",
      "  Batch 4,500  of  11,793.    Elapsed: 0:17:46.\n",
      "  Batch 5,000  of  11,793.    Elapsed: 0:19:44.\n",
      "  Batch 5,500  of  11,793.    Elapsed: 0:21:42.\n",
      "  Batch 6,000  of  11,793.    Elapsed: 0:23:40.\n",
      "  Batch 6,500  of  11,793.    Elapsed: 0:25:38.\n",
      "  Batch 7,000  of  11,793.    Elapsed: 0:27:37.\n",
      "  Batch 7,500  of  11,793.    Elapsed: 0:29:37.\n",
      "  Batch 8,000  of  11,793.    Elapsed: 0:31:36.\n",
      "  Batch 8,500  of  11,793.    Elapsed: 0:33:36.\n",
      "  Batch 9,000  of  11,793.    Elapsed: 0:35:39.\n",
      "  Batch 9,500  of  11,793.    Elapsed: 0:37:41.\n",
      "  Batch 10,000  of  11,793.    Elapsed: 0:39:42.\n",
      "  Batch 10,500  of  11,793.    Elapsed: 0:41:42.\n",
      "  Batch 11,000  of  11,793.    Elapsed: 0:43:40.\n",
      "  Batch 11,500  of  11,793.    Elapsed: 0:45:39.\n",
      "\n",
      "  Average training loss: 0.67\n",
      "  Training epcoh took: 0:46:48\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.61\n",
      "  Validation took: 0:03:12\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Batch   500  of  11,793.    Elapsed: 0:02:03.\n",
      "  Batch 1,000  of  11,793.    Elapsed: 0:04:02.\n",
      "  Batch 1,500  of  11,793.    Elapsed: 0:06:04.\n",
      "  Batch 2,000  of  11,793.    Elapsed: 0:08:08.\n",
      "  Batch 2,500  of  11,793.    Elapsed: 0:10:11.\n",
      "  Batch 3,000  of  11,793.    Elapsed: 0:12:15.\n",
      "  Batch 3,500  of  11,793.    Elapsed: 0:14:18.\n",
      "  Batch 4,000  of  11,793.    Elapsed: 0:16:22.\n",
      "  Batch 4,500  of  11,793.    Elapsed: 0:18:23.\n",
      "  Batch 5,000  of  11,793.    Elapsed: 0:20:24.\n",
      "  Batch 5,500  of  11,793.    Elapsed: 0:22:27.\n",
      "  Batch 6,000  of  11,793.    Elapsed: 0:24:31.\n",
      "  Batch 6,500  of  11,793.    Elapsed: 0:26:35.\n",
      "  Batch 7,000  of  11,793.    Elapsed: 0:28:36.\n",
      "  Batch 7,500  of  11,793.    Elapsed: 0:30:37.\n",
      "  Batch 8,000  of  11,793.    Elapsed: 0:32:34.\n",
      "  Batch 8,500  of  11,793.    Elapsed: 0:34:31.\n",
      "  Batch 9,000  of  11,793.    Elapsed: 0:36:27.\n",
      "  Batch 9,500  of  11,793.    Elapsed: 0:38:23.\n",
      "  Batch 10,000  of  11,793.    Elapsed: 0:40:20.\n",
      "  Batch 10,500  of  11,793.    Elapsed: 0:42:16.\n",
      "  Batch 11,000  of  11,793.    Elapsed: 0:44:13.\n",
      "  Batch 11,500  of  11,793.    Elapsed: 0:46:12.\n",
      "\n",
      "  Average training loss: 0.65\n",
      "  Training epcoh took: 0:47:22\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.67\n",
      "  Validation took: 0:03:08\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "  Batch   500  of  11,793.    Elapsed: 0:01:59.\n",
      "  Batch 1,000  of  11,793.    Elapsed: 0:03:59.\n",
      "  Batch 1,500  of  11,793.    Elapsed: 0:05:58.\n",
      "  Batch 2,000  of  11,793.    Elapsed: 0:07:57.\n",
      "  Batch 2,500  of  11,793.    Elapsed: 0:09:55.\n",
      "  Batch 3,000  of  11,793.    Elapsed: 0:11:54.\n",
      "  Batch 3,500  of  11,793.    Elapsed: 0:13:55.\n",
      "  Batch 4,000  of  11,793.    Elapsed: 0:15:54.\n",
      "  Batch 4,500  of  11,793.    Elapsed: 0:17:53.\n",
      "  Batch 5,000  of  11,793.    Elapsed: 0:19:52.\n",
      "  Batch 5,500  of  11,793.    Elapsed: 0:21:50.\n",
      "  Batch 6,000  of  11,793.    Elapsed: 0:23:48.\n",
      "  Batch 6,500  of  11,793.    Elapsed: 0:25:47.\n",
      "  Batch 7,000  of  11,793.    Elapsed: 0:27:46.\n",
      "  Batch 7,500  of  11,793.    Elapsed: 0:29:45.\n",
      "  Batch 8,000  of  11,793.    Elapsed: 0:31:45.\n",
      "  Batch 8,500  of  11,793.    Elapsed: 0:33:45.\n",
      "  Batch 9,000  of  11,793.    Elapsed: 0:35:44.\n",
      "  Batch 9,500  of  11,793.    Elapsed: 0:37:43.\n",
      "  Batch 10,000  of  11,793.    Elapsed: 0:39:42.\n",
      "  Batch 10,500  of  11,793.    Elapsed: 0:41:41.\n",
      "  Batch 11,000  of  11,793.    Elapsed: 0:43:40.\n",
      "  Batch 11,500  of  11,793.    Elapsed: 0:45:40.\n",
      "\n",
      "  Average training loss: 0.64\n",
      "  Training epcoh took: 0:46:51\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.66\n",
      "  Validation took: 0:03:09\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "#랜덤시드 고정\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "#그래디언트 초기화\n",
    "model.zero_grad()\n",
    "\n",
    "# 학습\n",
    "for epoch_i in range(0, epochs):\n",
    "\n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # 시작 시간 설정\n",
    "    t0 = time.time()\n",
    "\n",
    "    # 로스 초기화\n",
    "    total_loss = 0\n",
    "\n",
    "    # 훈련모드로 변경\n",
    "    model.train()\n",
    "\n",
    "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # 경과 정보 표시\n",
    "        if step % 500 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # 배치를 GPU에 넣음\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # 배치에서 데이터 추출\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        # Forward 수행\n",
    "        outputs = model(b_input_ids,\n",
    "                        token_type_ids=None,\n",
    "                        attention_mask=b_input_mask,\n",
    "                        labels=b_labels)\n",
    "\n",
    "        # 로스 구함\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # 총 로스 계산\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward 수행으로 그래디언트 계산\n",
    "        loss.backward()\n",
    "\n",
    "        # 그래디언트 클리핑\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # 그래디언트를 통해 가중치 파라미터 업데이트\n",
    "        optimizer.step()\n",
    "\n",
    "        # 스케줄러로 학습률 감소\n",
    "        scheduler.step()\n",
    "\n",
    "        # 그래디언트 초기화\n",
    "        model.zero_grad()\n",
    "\n",
    "    # 평균 로스 계산\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    #시작 시간 설정\n",
    "    t0 = time.time()\n",
    "\n",
    "    # 평가모드로 변경\n",
    "    model.eval()\n",
    "\n",
    "    # 변수 초기화\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "    for batch in validation_dataloader:\n",
    "        # 배치를 GPU에 넣음\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # 배치에서 데이터 추출\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        # 그래디언트 계산 안함\n",
    "        with torch.no_grad():\n",
    "            # Forward 수행\n",
    "            outputs = model(b_input_ids,\n",
    "                            token_type_ids=None,\n",
    "                            attention_mask=b_input_mask)\n",
    "\n",
    "        # 로스 구함\n",
    "        logits = outputs[0]\n",
    "\n",
    "        # CPU로 데이터 이동\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "torch.save(model,\"./data/model/bert-4.pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./data/model/bert_state-4.pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "import torch,gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "[101,\n 9521,\n 118741,\n 9952,\n 9435,\n 48549,\n 9812,\n 48446,\n 9361,\n 9645,\n 48345,\n 9294,\n 119137,\n 9633,\n 9087,\n 12638,\n 9113,\n 85836,\n 118671,\n 48549,\n 9638,\n 35465,\n 9565,\n 49543,\n 10013,\n 11287,\n 9137,\n 8843,\n 52560,\n 8898,\n 19653,\n 8887,\n 55670,\n 29805,\n 9299,\n 118744,\n 10739,\n 9233,\n 8847,\n 8887,\n 103155,\n 9638,\n 9559,\n 48549,\n 9299,\n 118744,\n 9638,\n 8847,\n 9137,\n 9645,\n 9633,\n 9664,\n 58931,\n 9954,\n 9588,\n 9633,\n 9765,\n 38631,\n 9960,\n 9689,\n 9435,\n 48549,\n 9011,\n 9655,\n 14040,\n 9248,\n 8932,\n 11903,\n 26737,\n 9689,\n 9435,\n 48549,\n 9542,\n 8888,\n 9487,\n 70122,\n 17138,\n 9638,\n 9647,\n 9043,\n 9519,\n 10739,\n 108366,\n 9633,\n 9996,\n 24974,\n 9960,\n 9565,\n 49543,\n 9559,\n 9645,\n 8932,\n 9685,\n 9632,\n 9812,\n 48446,\n 9645,\n 48345,\n 9457,\n 15184,\n 9332,\n 9128,\n 9911,\n 60479,\n 9294,\n 118905,\n 9619,\n 9202,\n 9580,\n 9043,\n 9717,\n 9632,\n 8934,\n 9638,\n 9332,\n 9128,\n 9968,\n 12692,\n 9744,\n 12692,\n 9318,\n 12508,\n 9575,\n 9479,\n 118856,\n 15184,\n 9689,\n 118920,\n 25503,\n 96567,\n 9664,\n 9640,\n 9812,\n 119372,\n 9186,\n 48653,\n 9909,\n 57346,\n 9080,\n 9072,\n 9612,\n 24989,\n 9619,\n 9559,\n 9080,\n 14423,\n 9546,\n 9708,\n 9812,\n 119372,\n 9186,\n 48653,\n 9122,\n 119351,\n 18392,\n 9202,\n 39629,\n 9317,\n 24989,\n 9365,\n 37712,\n 9559,\n 9186,\n 78136,\n 9157,\n 12030,\n 9638,\n 9379,\n 119277,\n 9202,\n 118916,\n 119375,\n 9954,\n 9367,\n 19855,\n 12310,\n 9233,\n 9568,\n 52363,\n 16139,\n 9812,\n 119372,\n 117,\n 9931,\n 12692,\n 117,\n 9186,\n 48653,\n 9987,\n 42337,\n 9487,\n 70122,\n 9434,\n 9539,\n 18784,\n 9647,\n 9634,\n 9664,\n 21928,\n 9954,\n 9102,\n 118683,\n 8848,\n 9379,\n 119285,\n 9555,\n 9634,\n 9059,\n 80331,\n 9450,\n 24982,\n 119335,\n 9113,\n 17342,\n 10739,\n 119327,\n 12692,\n 106065,\n 8917,\n 13890,\n 9379,\n 119285,\n 9689,\n 9637,\n 9186,\n 48653,\n 9583,\n 9937,\n 67527,\n 9689,\n 9637,\n 9542,\n 8888,\n 8843,\n 118983,\n 21614,\n 9731,\n 24974,\n 105197,\n 29805,\n 9565,\n 49543,\n 9559,\n 9664,\n 33188,\n 9954,\n 9519,\n 10739,\n 30005,\n 12692,\n 9801,\n 30873,\n 8888,\n 16758,\n 9087,\n 9637,\n 9519,\n 10739,\n 30005,\n 12692,\n 9801,\n 30873,\n 9202,\n 9324,\n 8888,\n 9993,\n 12945,\n 9954,\n 9041,\n 118710,\n 100,\n 9689,\n 12965,\n 9360,\n 8898,\n 9565,\n 49543,\n 9559,\n 9524,\n 118913,\n 9632,\n 9416,\n 105197,\n 9638,\n 9056,\n 9996,\n 18778,\n 9664,\n 9638,\n 8888,\n 9924,\n 11102,\n 71771,\n 12508,\n 8920,\n 119145,\n 8888,\n 9323,\n 118852,\n 9954,\n 9202,\n 118916,\n 119375,\n 9954,\n 9792,\n 16323,\n 119134,\n 9954,\n 9083,\n 18392,\n 12692,\n 9214,\n 9083,\n 41620,\n 9214,\n 9946,\n 20308,\n 118766,\n 9214,\n 9318,\n 119290,\n 12605,\n 9214,\n 102,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0]"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'tesnor'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_22292/2842611647.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m outputs = model(torch.tensor(input_ids[0]).to(device), token_type_ids=None,\n\u001B[1;32m----> 2\u001B[1;33m                       attention_mask=torch.tesnor(attention_masks[0]).to(device))\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'torch' has no attribute 'tesnor'"
     ]
    }
   ],
   "source": [
    "outputs = model(torch.tensor(input_ids[0]).to(device), token_type_ids=None,\n",
    "                      attention_mask=torch.tesnor(attention_masks[0]).to(device))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "data": {
      "text/plain": "512"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_ids[0])\n",
    "len(attention_masks[0])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def convert_input_data(sentences):\n",
    "\n",
    "    # BERT의 토크나이저로 문장을 토큰으로 분리\n",
    "    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "\n",
    "    # 입력 토큰의 최대 시퀀스 길이\n",
    "    MAX_LEN = 512\n",
    "\n",
    "    # 토큰을 숫자 인덱스로 변환\n",
    "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "\n",
    "    # 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n",
    "    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "    # 어텐션 마스크 초기화\n",
    "    attention_masks = []\n",
    "\n",
    "    # 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n",
    "    # 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n",
    "    for seq in input_ids:\n",
    "        seq_mask = [float(i>0) for i in seq]\n",
    "        attention_masks.append(seq_mask)\n",
    "\n",
    "    # 데이터를 파이토치의 텐서로 변환\n",
    "    inputs = torch.tensor(input_ids)\n",
    "    masks = torch.tensor(attention_masks)\n",
    "\n",
    "    return inputs, masks"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def test_sentences(sentences):\n",
    "\n",
    "    # 평가모드로 변경\n",
    "    model.eval()\n",
    "\n",
    "    # 문장을 입력 데이터로 변환\n",
    "    inputs, masks = convert_input_data(sentences)\n",
    "\n",
    "    # 데이터를 GPU에 넣음\n",
    "    b_input_ids = inputs.to(device)\n",
    "    b_input_mask = masks.to(device)\n",
    "\n",
    "    # 그래디언트 계산 안함\n",
    "    with torch.no_grad():\n",
    "        # Forward 수행\n",
    "        outputs = model(b_input_ids,\n",
    "                        token_type_ids=None,\n",
    "                        attention_mask=b_input_mask)\n",
    "\n",
    "    # 로스 구함\n",
    "    logits = outputs[0]\n",
    "\n",
    "    # CPU로 데이터 이동\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "\n",
    "    return logits"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "device = torch.device(\"cuda\")\n",
    "model = torch.load(\"data/model/bert-4.pt\")\n",
    "model.eval()\n",
    "logits = test_sentences([\"가을 축제 에 입 고 갈 스타일 로 코디 해 주 세요 치마 바지 원피스 중 어떤 옷 이 포함 된 코디 를 추천 해드릴까요 ? 원피스 나 치마 로 추천 해 주 세요 가을 에 입 기 좋 은 적당 한 두께 감 의 아우 터 와 함께 추천 해드릴까요 ? 네 상의 는 무늬 없 는 티 로 추천 해 드리 는 것 은 어떠신가요 ? 좋 습니다 얕 은 라운드 네크라인 슬림 한 일자 소매통 일자 형 암홀 손등 까지 내려오 는 소매 기장 허리선 까지 오 는 기장 전체 적 으로 슬림 한 라인 네크라인 재 원단 처리 소매 끝 과 밑단 삼봉 봉제 처리 앞 , 뒤 길 이 차이 없 는 일자 형 밑단 적당히 몸 에 붙 는 슬림 한 스타일 심플 하고 베이직 한 아이템 면 100 % 싱글 저 지 부드럽 고 편안 한 느낌 의 신축성 좋 음 두께 감 얇 음 베이지 다크 그레 이쉬 톤 의 내추럴 하 고 온화 한 느낌 편안 한 캐주얼 한 슬림 한 심플 한\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "numpy.float32"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(logits[0][1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "-0.2473096251487732"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[0][1] + 0.0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-2b894917",
   "language": "python",
   "display_name": "PyCharm (pythonProject2)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}